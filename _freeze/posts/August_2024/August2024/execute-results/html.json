{
  "hash": "3360dbd59db8e2e25386fb1e348c7ad1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Running R Computational Tasks\"\ndescription: \"Exploring efficient ways to run computational tasks in R, from background jobs to profiling, debugging, and parallelisation, with practical tips and examples.\"\nauthor: \"Nikita M.\"\ndate: \"2024-08-22\"\nformat:\n  html:\n    page-layout: article\n    toc: true\n    html-math-method: katex\n    highlight: tango\ntitle-block-banner: false\ncategories: [R-tips]\n---\n\n\n\n## Motivation\n\nRunning computationally expensive tasks in R can be challenging, especially when working with **large datasets** and **intensive operations**. This article provides **practical strategies** for efficiently handling background jobs, optimizing performance, debugging, and leveraging parallelization.\n\n## Addressing\n\nEfficient execution of computational tasks ensures that R processes run **without blocking user interaction**, effectively utilizing system resources. The **pyramid framework** below illustrates the **layers of computational efficiency** in R programming.\n\n![](media/pyramid.png){fig-align=\"center\"}\n\n[Source: Selina Baldauf](https://github.com/selinaZitrone/tools_and_tips/)\n\n------------------------------------------------------------------------\n\n## Running Background Jobs in R\n\n### **Example 1: Running an Iterative Task in the Background**\n\nBackground jobs allow **long-running computations** to execute independently, \nfreeing the **R console** for other tasks.  \n\n::::: columns\n::: {.column width=\"55%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\n# Simulate a large dataset\nset.seed(123)\nlarge_data <- data.frame(\n  id = 1:1e6,\n  value = rnorm(1e6)\n)\n\n# Perform some computationally intensive operations\nfor(i in 1:15) {\n  result <- large_data %>%\n    group_by(id %% 10) %>%\n    summarize(mean_value = mean(value))\n  Sys.sleep(2) # Simulate long-running process\n  cat(\"Running\", i, \"iteration.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning 1 iteration.\nRunning 2 iteration.\nRunning 3 iteration.\nRunning 4 iteration.\nRunning 5 iteration.\nRunning 6 iteration.\nRunning 7 iteration.\nRunning 8 iteration.\nRunning 9 iteration.\nRunning 10 iteration.\nRunning 11 iteration.\nRunning 12 iteration.\nRunning 13 iteration.\nRunning 14 iteration.\nRunning 15 iteration.\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Background job completed.\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBackground job completed.\n```\n\n\n:::\n:::\n\n\n:::\n::: {.column width=\"5%\"}\n:::\n::: {.column width=\"40%\"}\n    \n![](media/bg_job_settings.png){.lightbox}\n:::\n:::::\n\n### **Explanation:**\n\n-   `Sys.sleep(2)` **simulates** a time-consuming task.\n-   **Each iteration** performs a grouped summary operation.\n-   Running this **in the background** allows users to interact with R **without interruption**.\n\n------------------------------------------------------------------------\n\n## Responsible Use of Resources\n\nItâ€™s crucial to **balance computational demand** to prevent **overloading shared servers**.\n\n**Example:** The BSU servers allow **small to medium-sized tasks**, so large-scale simulations should be managed carefully.\n\n![](media/overloaded.jpg){.lightbox width=\"1100\"}\n\nðŸ“Œ **Best Practice:** Use **resource monitoring tools** (`top`, `htop`) to check CPU usage before launching intensive computations.\n\n------------------------------------------------------------------------\n\n# Code Optimization in R\n\n## Profiling Computational Performance\n\nUnderstanding where **R code spends most of its execution time** helps optimize functions.\n\n### **Example 2: Using `profvis()` to Analyze Execution Time**\n\n``` r\nlibrary(profvis)\n\nfunction_1 <- function(size) {\n  large_list <- lapply(1:size, function(x) rnorm(5000))\n  return(large_list)\n}\n\nfunction_2 <- function(iterations) {\n  result <- 0\n  for (i in 1:iterations) {\n    Sys.sleep(0.1) \n    result <- result + i\n  }\n  return(result)\n}\n\nprofvis({\n  function_1(10000)\n  function_2(30)\n})\n```\n\n### **Explanation:**\n\n-   `profvis()` visualizes **where time is spent** in an R script.\n-   Helps identify **slow functions** and optimize code for **better efficiency**.\n\n![](media/profvis.png){.lightbox}\n\n------------------------------------------------------------------------\n\n## Debugging R Code\n\n### **Example 3: Using `browser()` for Step-by-Step Debugging**\n\n``` r\nfoo <- function(x) {\n  browser()\n  return(x * 2)\n}\n\nfoo(10)\n```\n\n### **Explanation:**\n\n-   `browser()` allows **stepwise execution**, helping debug **unexpected errors**.\n-   The function pauses at `browser()`, enabling users to inspect variables interactively.\n\n![](media/browser.mp4)\n\n------------------------------------------------------------------------\n\n## Parallelization in R\n\n### **Example 4: Parallelizing Loops with `foreach`**\n\nUsing parallel computing **significantly reduces execution time**.\n\n::::: columns\n::: {.column width=\"45%\"}\n#### **Regular `for()` Loop**\n\n``` r\nresult <- NULL\n\nfor (i in 1:1000) {\n  result[i] <- rnorm(1)^2 \n}\n```\n:::\n::: {.column width=\"5%\"}\n\n:::\n::: {.column width=\"50%\"}\n#### **Parallelized `foreach()` Loop**\n\n``` r\nlibrary(foreach)\nlibrary(doParallel)\n\ncl <- makeCluster(parallel::detectCores() - 1)\nregisterDoParallel(cl)\n\nresult <- foreach(i = 1:1000, .combine = 'c') %dopar% {\n  rnorm(1)^2 \n}\n\nstopCluster(cl)\n```\n:::\n:::::\n\n### **Explanation:**\n\n-   **Standard `for()` loops** execute sequentially, which is slow for large-scale tasks.\n-   **`foreach()` with `doParallel`** allows parallel execution, **leveraging multiple CPU cores**.\n-   `makeCluster(parallel::detectCores() - 1)` ensures all but one core are used, **preventing system overload**.\n\nðŸ“Œ **Best Practice:** Always **test code sequentially first** before enabling parallel execution to debug potential issues.\n\n------------------------------------------------------------------------\n\n### **Conclusion**\n\nBy implementing these techniques, you can **run computational tasks in R more efficiently**, reducing runtime and improving workflow performance. ðŸš€\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}